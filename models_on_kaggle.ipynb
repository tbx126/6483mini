{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-14T05:58:12.156062Z",
     "iopub.status.busy": "2025-11-14T05:58:12.155885Z",
     "iopub.status.idle": "2025-11-14T05:58:13.900783Z",
     "shell.execute_reply": "2025-11-14T05:58:13.900160Z",
     "shell.execute_reply.started": "2025-11-14T05:58:12.156045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:42:27.566992Z",
     "iopub.status.busy": "2025-11-14T07:42:27.566426Z",
     "iopub.status.idle": "2025-11-14T07:42:27.592690Z",
     "shell.execute_reply": "2025-11-14T07:42:27.592001Z",
     "shell.execute_reply.started": "2025-11-14T07:42:27.566969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cat vs Dog Multi-Model Classification (IPython Notebook version)\n",
    "Each model runs in independent cells, results are aggregated at the end\n",
    "\"\"\"\n",
    "\n",
    "# Import dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU detection\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Global configuration (shared across all models)\n",
    "class Config:\n",
    "    # Data configuration\n",
    "    DATASET_NAME = 'Aurora1609/cat_vs_dog'\n",
    "    IMG_SIZE = 224\n",
    "    BATCH_SIZE = 32  \n",
    "    NUM_WORKERS = 0  \n",
    "    PIN_MEMORY = False  \n",
    "    \n",
    "    # Training configuration\n",
    "    NUM_EPOCHS = 20\n",
    "    NUM_CLASSES = 2\n",
    "    LEARNING_RATE = 0.0001\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    LR_SCHEDULER_PATIENCE = 3\n",
    "    LR_SCHEDULER_FACTOR = 0.5\n",
    "\n",
    "    # Save configuration\n",
    "    MODEL_SAVE_DIR = './saved_models'\n",
    "    VIS_SAVE_DIR = './visualization_results'\n",
    "    CLASS_NAMES = ['cat', 'dog']\n",
    "    NUM_SAMPLE_GRID = 16\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# Create save directories\n",
    "os.makedirs(cfg.MODEL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(cfg.VIS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Global dictionary: stores results for all models (val_acc, test_acc, history)\n",
    "all_model_results = {}\n",
    "\n",
    "# Visualization\n",
    "def plot_single_model_curve(history, model_name, save_path):\n",
    "    \"\"\"Plot training curves for a single model\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Accuracy curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_acc'], 'b-o', label='Train Acc', markersize=4)\n",
    "    plt.plot(history['val_acc'], 'r-o', label='Val Acc', markersize=4)\n",
    "    plt.title(f'{model_name} - Accuracy Curve', fontsize=12)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_loss'], 'b-o', label='Train Loss', markersize=4)\n",
    "    plt.plot(history['val_loss'], 'r-o', label='Val Loss', markersize=4)\n",
    "    plt.title(f'{model_name} - Loss Curve', fontsize=12)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ Training curve saved: {os.path.basename(save_path)}\")\n",
    "\n",
    "def plot_confusion_matrix(all_true, all_pred, class_names, model_name, save_path, split='Val Set'):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(all_true, all_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt='d', cmap='Blues',\n",
    "        xticklabels=class_names, yticklabels=class_names,\n",
    "        cbar_kws={'label': 'Number of Samples'}\n",
    "    )\n",
    "    plt.title(f'{model_name} - Confusion Matrix ({split})', fontsize=14)\n",
    "    plt.xlabel('Predicted', fontsize=12)\n",
    "    plt.ylabel('True', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ Confusion matrix saved: {os.path.basename(save_path)}\")\n",
    "\n",
    "def plot_sample_analysis(model, val_loader, class_names, device, model_name, save_dir, num_samples=16):\n",
    "    \"\"\"Plot sample analysis (correct/incorrect predictions)\"\"\"\n",
    "    model.eval()\n",
    "    correct_imgs, correct_lbls, correct_preds = [], [], []\n",
    "    incorrect_imgs, incorrect_lbls, incorrect_preds = [], [], []\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).to(device).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).to(device).view(3, 1, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            lbls = lbls.to(device)\n",
    "            preds = model(imgs).argmax(dim=1)\n",
    "            for img, lbl, pred in zip(imgs, lbls, preds):\n",
    "                if lbl == pred:\n",
    "                    correct_imgs.append(img)\n",
    "                    correct_lbls.append(lbl)\n",
    "                    correct_preds.append(pred)\n",
    "                else:\n",
    "                    incorrect_imgs.append(img)\n",
    "                    incorrect_lbls.append(lbl)\n",
    "                    incorrect_preds.append(pred)\n",
    "            if len(correct_imgs)>=num_samples and len(incorrect_imgs)>=num_samples:\n",
    "                break\n",
    "\n",
    "    # Correct predictions plot\n",
    "    if len(correct_imgs)>=num_samples:\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "        fig.suptitle(f'{model_name} - Correct Predictions (Val Set)', fontsize=18, y=0.95)\n",
    "        for idx, (img, t_lbl, p_lbl) in enumerate(zip(correct_imgs[:num_samples], correct_lbls[:num_samples], correct_preds[:num_samples])):\n",
    "            img = img.squeeze().cpu() * std.cpu() + mean.cpu()\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "            ax = axes[idx//4, idx%4]\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"True: {class_names[t_lbl.item()]}\\nPred: {class_names[p_lbl.item()]}\", color='green', fontsize=12, pad=10)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "        plt.savefig(os.path.join(save_dir, f\"{model_name}_correct_samples.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"✅ Correct predictions saved: {model_name}_correct_samples.png\")\n",
    "    \n",
    "    # Incorrect predictions plot\n",
    "    if len(incorrect_imgs)>=num_samples:\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "        fig.suptitle(f'{model_name} - Incorrect Predictions (Val Set)', fontsize=18, y=0.95)\n",
    "        for idx, (img, t_lbl, p_lbl) in enumerate(zip(incorrect_imgs[:num_samples], incorrect_lbls[:num_samples], incorrect_preds[:num_samples])):\n",
    "            img = img.squeeze().cpu() * std.cpu() + mean.cpu()\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "            ax = axes[idx//4, idx%4]\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"True: {class_names[t_lbl.item()]}\\nPred: {class_names[p_lbl.item()]}\", color='red', fontsize=12, pad=10)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "        plt.savefig(os.path.join(save_dir, f\"{model_name}_incorrect_samples.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"✅ Incorrect predictions saved: {model_name}_incorrect_samples.png\")\n",
    "    else:\n",
    "        print(f\"⚠️ {model_name}: Not enough incorrect samples, skipping incorrect samples plot\")\n",
    "\n",
    "# Training/validation\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(loader, desc='Training', ncols=100)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        pbar.set_postfix({'loss': f'{running_loss/total:.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
    "    return running_loss / total, 100 * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    pbar = tqdm(loader, desc='Validation', ncols=100)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_true.extend(labels.cpu().numpy())\n",
    "            all_pred.extend(predicted.cpu().numpy())\n",
    "            pbar.set_postfix({'loss': f'{running_loss/total:.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
    "    return running_loss / total, 100 * correct / total, all_true, all_pred\n",
    "\n",
    "print(\"✅ Cell 1: Dependencies and configuration completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T06:23:24.216563Z",
     "iopub.status.busy": "2025-11-14T06:23:24.215905Z",
     "iopub.status.idle": "2025-11-14T06:23:24.771810Z",
     "shell.execute_reply": "2025-11-14T06:23:24.771210Z",
     "shell.execute_reply.started": "2025-11-14T06:23:24.216537Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset class with error handling\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            item = self.dataset[idx]\n",
    "            image = item['image'].convert('RGB')\n",
    "            label = item['label']\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to load sample {idx}: {e}, returning fallback sample\")\n",
    "\n",
    "            # Return first sample as fallback to prevent crash\n",
    "            item = self.dataset[0]\n",
    "            image = item['image'].convert('RGB')\n",
    "            label = item['label']\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "\n",
    "# Data preprocessing (shared across all models)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(cfg.IMG_SIZE, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((cfg.IMG_SIZE, cfg.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "print(f\"Loading dataset: {cfg.DATASET_NAME} (with built-in train/val/test splits)...\")\n",
    "dataset = load_dataset(cfg.DATASET_NAME)\n",
    "train_hf = dataset['train']\n",
    "val_hf = dataset['val']\n",
    "test_hf = dataset['test']\n",
    "\n",
    "# Wrap datasets\n",
    "train_dataset = CatDogDataset(train_hf, train_transform)\n",
    "val_dataset = CatDogDataset(val_hf, val_test_transform)\n",
    "test_dataset = CatDogDataset(test_hf, val_test_transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True,\n",
    "    num_workers=cfg.NUM_WORKERS, pin_memory=cfg.PIN_MEMORY, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "    num_workers=cfg.NUM_WORKERS, pin_memory=cfg.PIN_MEMORY\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "    num_workers=cfg.NUM_WORKERS, pin_memory=cfg.PIN_MEMORY\n",
    ")\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"\\nDataset split information:\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Test samples: {len(test_dataset)}\")\n",
    "print(f\"  Classes: {cfg.CLASS_NAMES}\")\n",
    "\n",
    "print(\"✅ Cell2: Data loading complete! Shared across all models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T06:24:21.418458Z",
     "iopub.status.busy": "2025-11-14T06:24:21.417718Z",
     "iopub.status.idle": "2025-11-14T07:27:36.405121Z",
     "shell.execute_reply": "2025-11-14T07:27:36.404449Z",
     "shell.execute_reply.started": "2025-11-14T06:24:21.418430Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model building\n",
    "def build_resnet18(num_classes=2, pretrained=True):\n",
    "    if pretrained:\n",
    "        try:\n",
    "            model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        except:\n",
    "            model = models.resnet18(pretrained=True)\n",
    "    else:\n",
    "        model = models.resnet18(pretrained=False)\n",
    "    \n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "# Initialize model\n",
    "model_name = 'resnet18'\n",
    "print(f\"===== Training model: {model_name} =====\")\n",
    "model = build_resnet18(num_classes=cfg.NUM_CLASSES, pretrained=True)\n",
    "print(f\"✅ {model_name} initialized with pretrained weights\")\n",
    "\n",
    "# Training configuration\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=cfg.WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=cfg.LR_SCHEDULER_FACTOR, patience=cfg.LR_SCHEDULER_PATIENCE, verbose=True\n",
    ")\n",
    "\n",
    "# Training history\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_all_true = []\n",
    "best_all_pred = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg.NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{cfg.NUM_EPOCHS}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, all_true, all_pred = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_all_true = all_true\n",
    "        best_all_pred = all_pred\n",
    "        model_save_path = os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'val_acc': best_val_acc,\n",
    "            'history': history\n",
    "        }, model_save_path)\n",
    "        print(f\"[SAVED] Best model (Val accuracy: {best_val_acc:.2f}%) → {os.path.basename(model_save_path)}\")\n",
    "    \n",
    "    print(f\"Epoch summary: train_loss={train_loss:.4f} train_acc={train_acc:.2f}% | \"\n",
    "          f\"val_loss={val_loss:.4f} val_acc={val_acc:.2f}% | lr={current_lr:.6f}\")\n",
    "\n",
    "# Visualizations\n",
    "print(f\"\\n===== Generating {model_name} visualizations =====\")\n",
    "curve_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_training_curves.png\")\n",
    "plot_single_model_curve(history, model_name, curve_path)\n",
    "\n",
    "cm_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_val_confusion_matrix.png\")\n",
    "plot_confusion_matrix(best_all_true, best_all_pred, cfg.CLASS_NAMES, model_name, cm_path, split='Val Set')\n",
    "\n",
    "plot_sample_analysis(model, val_loader, cfg.CLASS_NAMES, device, model_name, cfg.VIS_SAVE_DIR, cfg.NUM_SAMPLE_GRID)\n",
    "\n",
    "# Save results\n",
    "all_model_results[model_name] = {\n",
    "    'val_acc': best_val_acc,\n",
    "    'history': history,\n",
    "    'model_path': os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ {model_name} training completed!\")\n",
    "print(f\"Trained models: {list(all_model_results.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:42:35.847832Z",
     "iopub.status.busy": "2025-11-14T07:42:35.847312Z",
     "iopub.status.idle": "2025-11-14T07:42:49.833138Z",
     "shell.execute_reply": "2025-11-14T07:42:49.832464Z",
     "shell.execute_reply.started": "2025-11-14T07:42:35.847811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate visualization analysis for this model\n",
    "print(f\"\\n===== Generating visualization analysis for {model_name} =====\")\n",
    "\n",
    "# Training curves\n",
    "curve_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_training_curves.png\")\n",
    "plot_single_model_curve(history, model_name, curve_path)\n",
    "\n",
    "# Confusion matrix (Val set)\n",
    "cm_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_val_confusion_matrix.png\")\n",
    "plot_confusion_matrix(best_all_true, best_all_pred, cfg.CLASS_NAMES, model_name, cm_path, split='Val Set')\n",
    "\n",
    "# Sample analysis\n",
    "plot_sample_analysis(model, val_loader, cfg.CLASS_NAMES, device, model_name, cfg.VIS_SAVE_DIR, cfg.NUM_SAMPLE_GRID)\n",
    "\n",
    "# Save results\n",
    "all_model_results[model_name] = {\n",
    "    'val_acc': best_val_acc,\n",
    "    'history': history,\n",
    "    'model_path': os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ {model_name} training and analysis completed! Results saved to global dictionary\")\n",
    "print(f\"Currently trained models: {list(all_model_results.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:42:59.750624Z",
     "iopub.status.busy": "2025-11-14T07:42:59.750349Z",
     "iopub.status.idle": "2025-11-14T07:43:22.481602Z",
     "shell.execute_reply": "2025-11-14T07:43:22.480711Z",
     "shell.execute_reply.started": "2025-11-14T07:42:59.750606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Display and save ResNet analysis summary\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "model_name = 'resnet18'\n",
    "vis_dir = cfg.VIS_SAVE_DIR\n",
    "\n",
    "# Define image paths\n",
    "image_paths = {\n",
    "    'Accuracy': os.path.join(vis_dir, f\"{model_name}_training_curves.png\"),\n",
    "    'Val Confusion Matrix': os.path.join(vis_dir, f\"{model_name}_val_confusion_matrix.png\"),\n",
    "    'Correct Samples': os.path.join(vis_dir, f\"{model_name}_correct_samples.png\"),\n",
    "    'Incorrect Samples': os.path.join(vis_dir, f\"{model_name}_incorrect_samples.png\")\n",
    "}\n",
    "\n",
    "# Create 2x2 subplot layout\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Load and display images\n",
    "for idx, (title, path) in enumerate(image_paths.items()):\n",
    "    if os.path.exists(path):\n",
    "        img = mpimg.imread(path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(title, fontsize=16, pad=20)\n",
    "        axes[idx].axis('off')\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, f\"Image not found: {title}\\nPath: {path}\", \n",
    "                      ha='center', va='center', fontsize=12, wrap=True)\n",
    "        axes[idx].set_title(title, fontsize=16, pad=20)\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.suptitle(f'ResNet18 Analysis', fontsize=20, y=0.98)\n",
    "\n",
    "# Save summary figure\n",
    "save_path = os.path.join(vis_dir, f\"{model_name}_analysis_summary.png\")\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"Summary figure saved: {save_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Optional: Save individual high-resolution images\n",
    "def save_single_image(image_title, image_path, save_dir):\n",
    "    if os.path.exists(image_path):\n",
    "        img = mpimg.imread(image_path)\n",
    "        save_path = os.path.join(save_dir, f\"{model_name}_{image_title.replace(' ', '_')}_highres.png\")\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'ResNet18 - {image_title}', fontsize=18)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(f\"Individual figure saved: {save_path}\")\n",
    "    else:\n",
    "        print(f\"Image not found: {image_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_resnet50(num_classes=2, pretrained=True):\n",
    "    if pretrained:\n",
    "        try:\n",
    "            model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        except:\n",
    "            model = models.resnet50(pretrained=True)\n",
    "    else:\n",
    "        model = models.resnet50(pretrained=False)\n",
    "    \n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "# Initialize\n",
    "model_name = 'resnet50'\n",
    "print(f\"===== Training model: {model_name} =====\")\n",
    "model = build_resnet50(num_classes=cfg.NUM_CLASSES, pretrained=True)\n",
    "print(f\"✅ {model_name} model initialized (pretrained weights: True)\")\n",
    "\n",
    "# Training configuration\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=cfg.WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=cfg.LR_SCHEDULER_FACTOR, patience=cfg.LR_SCHEDULER_PATIENCE, verbose=True\n",
    ")\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_all_true = []\n",
    "best_all_pred = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg.NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{cfg.NUM_EPOCHS}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, all_true, all_pred = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_all_true = all_true\n",
    "        best_all_pred = all_pred\n",
    "        \n",
    "        model_save_path = os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'val_acc': best_val_acc,\n",
    "            'history': history\n",
    "        }, model_save_path)\n",
    "        print(f\"[SAVED] Best model (Val Acc: {best_val_acc:.2f}%) → {os.path.basename(model_save_path)}\")\n",
    "    \n",
    "    print(f\"Epoch Summary: Train Loss={train_loss:.4f} Train Acc={train_acc:.2f}% | \"\n",
    "          f\"Val Loss={val_loss:.4f} Val Acc={val_acc:.2f}% | LR={current_lr:.6f}\")\n",
    "\n",
    "# Generate visualizations\n",
    "print(f\"\\n===== Generating {model_name} visualizations =====\")\n",
    "curve_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_training_curves.png\")\n",
    "plot_single_model_curve(history, model_name, curve_path)\n",
    "\n",
    "cm_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_val_confusion_matrix.png\")\n",
    "plot_confusion_matrix(best_all_true, best_all_pred, cfg.CLASS_NAMES, model_name, cm_path, split='Val Set')\n",
    "\n",
    "plot_sample_analysis(model, val_loader, cfg.CLASS_NAMES, device, model_name, cfg.VIS_SAVE_DIR, cfg.NUM_SAMPLE_GRID)\n",
    "\n",
    "# Save results\n",
    "all_model_results[model_name] = {\n",
    "    'val_acc': best_val_acc,\n",
    "    'history': history,\n",
    "    'model_path': os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ {model_name} training and analysis completed!\")\n",
    "print(f\"Trained models: {list(all_model_results.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T07:45:16.247012Z",
     "iopub.status.busy": "2025-11-14T07:45:16.246415Z",
     "iopub.status.idle": "2025-11-14T10:30:56.998917Z",
     "shell.execute_reply": "2025-11-14T10:30:56.998119Z",
     "shell.execute_reply.started": "2025-11-14T07:45:16.246986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model building\n",
    "def build_vgg16(num_classes=2, pretrained=True):\n",
    "    if pretrained:\n",
    "        try:\n",
    "            model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "        except:\n",
    "            model = models.vgg16(pretrained=True)\n",
    "    else:\n",
    "        model = models.vgg16(pretrained=False)\n",
    "    \n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "# Initialize model\n",
    "model_name = 'vgg16'\n",
    "print(f\"===== Training model: {model_name} =====\")\n",
    "model = build_vgg16(num_classes=cfg.NUM_CLASSES, pretrained=True)\n",
    "print(f\"✅ {model_name} model initialized (pretrained weights: True)\")\n",
    "\n",
    "# Training configuration\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=cfg.WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=cfg.LR_SCHEDULER_FACTOR, patience=cfg.LR_SCHEDULER_PATIENCE, verbose=True\n",
    ")\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_all_true = []\n",
    "best_all_pred = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg.NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{cfg.NUM_EPOCHS}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, all_true, all_pred = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_all_true = all_true\n",
    "        best_all_pred = all_pred\n",
    "        model_save_path = os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'val_acc': best_val_acc,\n",
    "            'history': history\n",
    "        }, model_save_path)\n",
    "        print(f\"[SAVED] Best model (Val accuracy: {best_val_acc:.2f}%) → {os.path.basename(model_save_path)}\")\n",
    "    \n",
    "    print(f\"Epoch summary: train_loss={train_loss:.4f} train_acc={train_acc:.2f}% | \"\n",
    "          f\"val_loss={val_loss:.4f} val_acc={val_acc:.2f}% | lr={current_lr:.6f}\")\n",
    "\n",
    "# Generate visualization analysis\n",
    "print(f\"\\n===== Generating {model_name} visualization analysis =====\")\n",
    "curve_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_training_curves.png\")\n",
    "plot_single_model_curve(history, model_name, curve_path)\n",
    "\n",
    "cm_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_val_confusion_matrix.png\")\n",
    "plot_confusion_matrix(best_all_true, best_all_pred, cfg.CLASS_NAMES, model_name, cm_path, split='Val Set')\n",
    "\n",
    "plot_sample_analysis(model, val_loader, cfg.CLASS_NAMES, device, model_name, cfg.VIS_SAVE_DIR, cfg.NUM_SAMPLE_GRID)\n",
    "\n",
    "# Save results\n",
    "all_model_results[model_name] = {\n",
    "    'val_acc': best_val_acc,\n",
    "    'history': history,\n",
    "    'model_path': os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ {model_name} training and analysis completed!\")\n",
    "print(f\"Trained models: {list(all_model_results.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T10:31:32.446867Z",
     "iopub.status.busy": "2025-11-14T10:31:32.446139Z",
     "iopub.status.idle": "2025-11-14T10:31:55.219248Z",
     "shell.execute_reply": "2025-11-14T10:31:55.218310Z",
     "shell.execute_reply.started": "2025-11-14T10:31:32.446844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Display and save ResNet50 analysis summary\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "model_name = 'vgg16'\n",
    "vis_dir = cfg.VIS_SAVE_DIR\n",
    "\n",
    "image_paths = {\n",
    "    'Accuracy': os.path.join(vis_dir, f\"{model_name}_training_curves.png\"),\n",
    "    'Val confusion matrix': os.path.join(vis_dir, f\"{model_name}_val_confusion_matrix.png\"),\n",
    "    'Correct sample': os.path.join(vis_dir, f\"{model_name}_correct_samples.png\"),\n",
    "    'Incorrect sample': os.path.join(vis_dir, f\"{model_name}_incorrect_samples.png\")\n",
    "}\n",
    "\n",
    "# Create subplot layout (2x2 grid)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Load and display images\n",
    "for idx, (title, path) in enumerate(image_paths.items()):\n",
    "    if os.path.exists(path):\n",
    "        img = mpimg.imread(path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(title, fontsize=16, pad=20)\n",
    "        axes[idx].axis('off')\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, f\"Image not found: {title}\\nPath: {path}\", \n",
    "                      ha='center', va='center', fontsize=12, wrap=True)\n",
    "        axes[idx].set_title(title, fontsize=16, pad=20)\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.suptitle(f'ResNet18 analysis', fontsize=20, y=0.98)\n",
    "\n",
    "# Save summary figure\n",
    "save_path = os.path.join(vis_dir, f\"{model_name}_analysis_summary.png\")\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(f\"Summary saved: {save_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Optional: Save individual high-resolution images\n",
    "def save_single_image(image_title, image_path, save_dir):\n",
    "    if os.path.exists(image_path):\n",
    "        img = mpimg.imread(image_path)\n",
    "        save_path = os.path.join(save_dir, f\"{model_name}_{image_title.replace(' ', '_')}_highres.png\")\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'ResNet50 - {image_title}', fontsize=18)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(f\"Individual image saved: {save_path}\")\n",
    "    else:\n",
    "        print(f\"Image not found: {image_title}\")\n",
    "\n",
    "print(f\"\\nFiles saved in: {vis_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T12:34:26.482190Z",
     "iopub.status.busy": "2025-11-14T12:34:26.481623Z",
     "iopub.status.idle": "2025-11-14T12:34:27.511471Z",
     "shell.execute_reply": "2025-11-14T12:34:27.510339Z",
     "shell.execute_reply.started": "2025-11-14T12:34:26.482133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_convnext(num_classes=2, pretrained=True):\n",
    "    if pretrained:\n",
    "        try:\n",
    "            model = models.convnext_small(weights=models.ConvNeXt_Small_Weights.DEFAULT)\n",
    "        except:\n",
    "            model = models.convnext_small(pretrained=True)\n",
    "    else:\n",
    "        model = models.convnext_small(pretrained=False)\n",
    "    \n",
    "    # Modify final classifier layer\n",
    "    in_features = model.classifier[2].in_features\n",
    "    model.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "# Initialize model\n",
    "model_name = 'convnext'\n",
    "print(f\"===== Training Model: {model_name} =====\")\n",
    "model = build_convnext(num_classes=cfg.NUM_CLASSES, pretrained=True)\n",
    "print(f\"✅ {model_name} model initialized (pretrained: True)\")\n",
    "\n",
    "# Training configuration\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=cfg.WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=cfg.LR_SCHEDULER_FACTOR, patience=cfg.LR_SCHEDULER_PATIENCE, verbose=True\n",
    ")\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_all_true = []\n",
    "best_all_pred = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg.NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{cfg.NUM_EPOCHS}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, all_true, all_pred = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_all_true = all_true\n",
    "        best_all_pred = all_pred\n",
    "        model_save_path = os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'val_acc': best_val_acc,\n",
    "            'history': history\n",
    "        }, model_save_path)\n",
    "        print(f\"[SAVED] Best model (Val Acc: {best_val_acc:.2f}%) → {os.path.basename(model_save_path)}\")\n",
    "    \n",
    "    print(f\"Epoch Summary: Train Loss={train_loss:.4f} Train Acc={train_acc:.2f}% | \"\n",
    "          f\"Val Loss={val_loss:.4f} Val Acc={val_acc:.2f}% | LR={current_lr:.6f}\")\n",
    "\n",
    "# Generate visualizations\n",
    "print(f\"\\n===== Generating {model_name} Visualizations =====\")\n",
    "curve_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_training_curves.png\")\n",
    "plot_single_model_curve(history, model_name, curve_path)\n",
    "\n",
    "cm_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_val_confusion_matrix.png\")\n",
    "plot_confusion_matrix(best_all_true, best_all_pred, cfg.CLASS_NAMES, model_name, cm_path, split='Val Set')\n",
    "\n",
    "plot_sample_analysis(model, val_loader, cfg.CLASS_NAMES, device, model_name, cfg.VIS_SAVE_DIR, cfg.NUM_SAMPLE_GRID)\n",
    "\n",
    "# Save results\n",
    "all_model_results[model_name] = {\n",
    "    'val_acc': best_val_acc,\n",
    "    'history': history,\n",
    "    'model_path': os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ {model_name} training completed! Results saved\")\n",
    "print(f\"Trained models: {list(all_model_results.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T10:32:15.136708Z",
     "iopub.status.busy": "2025-11-14T10:32:15.136430Z",
     "iopub.status.idle": "2025-11-14T11:50:38.705865Z",
     "shell.execute_reply": "2025-11-14T11:50:38.705033Z",
     "shell.execute_reply.started": "2025-11-14T10:32:15.136689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_efficientnet(num_classes=2, pretrained=True):\n",
    "    if pretrained:\n",
    "        try:\n",
    "            model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        except:\n",
    "            model = models.efficientnet_b0(pretrained=True)\n",
    "    else:\n",
    "        model = models.efficientnet_b0(pretrained=False)\n",
    "    \n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "# Initialize model\n",
    "model_name = 'efficientnet'\n",
    "print(f\"===== Training model: {model_name} =====\")\n",
    "model = build_efficientnet(num_classes=cfg.NUM_CLASSES, pretrained=True)\n",
    "print(f\"✅ {model_name} model initialized (pretrained weights: True)\")\n",
    "\n",
    "# Training configuration\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=cfg.WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=cfg.LR_SCHEDULER_FACTOR, patience=cfg.LR_SCHEDULER_PATIENCE, verbose=True\n",
    ")\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_all_true = []\n",
    "best_all_pred = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg.NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{cfg.NUM_EPOCHS}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, all_true, all_pred = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_all_true = all_true\n",
    "        best_all_pred = all_pred\n",
    "        model_save_path = os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'val_acc': best_val_acc,\n",
    "            'history': history\n",
    "        }, model_save_path)\n",
    "        print(f\"[SAVED] Best model (Val accuracy: {best_val_acc:.2f}%) → {os.path.basename(model_save_path)}\")\n",
    "    \n",
    "    print(f\"Epoch summary: train_loss={train_loss:.4f} train_acc={train_acc:.2f}% | \"\n",
    "          f\"val_loss={val_loss:.4f} val_acc={val_acc:.2f}% | lr={current_lr:.6f}\")\n",
    "\n",
    "# Generate visualization analysis\n",
    "print(f\"\\n===== Generating {model_name} visualization analysis =====\")\n",
    "curve_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_training_curves.png\")\n",
    "plot_single_model_curve(history, model_name, curve_path)\n",
    "cm_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_val_confusion_matrix.png\")\n",
    "plot_confusion_matrix(best_all_true, best_all_pred, cfg.CLASS_NAMES, model_name, cm_path, split='Val Set')\n",
    "plot_sample_analysis(model, val_loader, cfg.CLASS_NAMES, device, model_name, cfg.VIS_SAVE_DIR, cfg.NUM_SAMPLE_GRID)\n",
    "\n",
    "# Save results to global dictionary\n",
    "all_model_results[model_name] = {\n",
    "    'val_acc': best_val_acc,\n",
    "    'history': history,\n",
    "    'model_path': os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ {model_name} training and analysis complete! Results saved to global dictionary\")\n",
    "print(f\"Currently trained models: {list(all_model_results.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T11:50:55.811755Z",
     "iopub.status.busy": "2025-11-14T11:50:55.811108Z",
     "iopub.status.idle": "2025-11-14T11:51:19.727730Z",
     "shell.execute_reply": "2025-11-14T11:51:19.726923Z",
     "shell.execute_reply.started": "2025-11-14T11:50:55.811727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Display and save all analysis plots for the model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "model_name = 'efficientnet'\n",
    "vis_dir = cfg.VIS_SAVE_DIR\n",
    "\n",
    "image_paths = {\n",
    "    'Accuracy': os.path.join(vis_dir, f\"{model_name}_training_curves.png\"),\n",
    "    'Val confusion matrix': os.path.join(vis_dir, f\"{model_name}_val_confusion_matrix.png\"),\n",
    "    'Correct sample': os.path.join(vis_dir, f\"{model_name}_correct_samples.png\"),\n",
    "    'Incorrect sample': os.path.join(vis_dir, f\"{model_name}_incorrect_samples.png\")\n",
    "}\n",
    "\n",
    "# Create 2x2 subplot layout\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (title, path) in enumerate(image_paths.items()):\n",
    "    if os.path.exists(path):\n",
    "        img = mpimg.imread(path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(title, fontsize=16, pad=20)\n",
    "        axes[idx].axis('off')\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, f\"❌ {title} not found\\nPath: {path}\", \n",
    "                      ha='center', va='center', fontsize=12, wrap=True)\n",
    "        axes[idx].set_title(title, fontsize=16, pad=20)\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.suptitle(f'{model_name} Analysis', fontsize=20, y=0.98)\n",
    "\n",
    "# Save summary plot\n",
    "save_path = os.path.join(vis_dir, f\"{model_name}_analysis_summary.png\")\n",
    "plt.savefig(\n",
    "    save_path, \n",
    "    dpi=300,\n",
    "    bbox_inches='tight',\n",
    "    facecolor='white'\n",
    ")\n",
    "print(f\"✅ Summary plot saved: {save_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Optional: Save individual plots in high resolution\n",
    "def save_single_image(image_title, image_path, save_dir):\n",
    "    if os.path.exists(image_path):\n",
    "        img = mpimg.imread(image_path)\n",
    "        save_path = os.path.join(save_dir, f\"{model_name}_{image_title.replace(' ', '_')}_highres.png\")\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'{model_name} - {image_title}', fontsize=18)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(f\"✅ Individual plot saved: {save_path}\")\n",
    "    else:\n",
    "        print(f\"❌ {image_title} not found, cannot save\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T11:57:46.522960Z",
     "iopub.status.busy": "2025-11-14T11:57:46.522664Z",
     "iopub.status.idle": "2025-11-14T11:57:50.101864Z",
     "shell.execute_reply": "2025-11-14T11:57:50.101181Z",
     "shell.execute_reply.started": "2025-11-14T11:57:46.522939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check for trained models\n",
    "if len(all_model_results) == 0:\n",
    "    print(\"❌ No trained models available! Please run Cell3~Cell7 to train models first\")\n",
    "else:\n",
    "    # Find best model\n",
    "    sorted_models = sorted(all_model_results.items(), key=lambda x: x[1]['val_acc'], reverse=True)\n",
    "    best_model_name = sorted_models[0][0]\n",
    "    best_model_result = sorted_models[0][1]\n",
    "    print(f\"===== Best Model: {best_model_name} (Val Accuracy: {best_model_result['val_acc']:.2f}%) =====\")\n",
    "    \n",
    "    # Load best model\n",
    "    print(f\"\\n1. Loading best model...\")\n",
    "    if best_model_name == 'resnet18':\n",
    "        from torchvision import models\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, cfg.NUM_CLASSES)\n",
    "    elif best_model_name == 'resnet50':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        in_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(in_features, cfg.NUM_CLASSES)\n",
    "    elif best_model_name == 'vgg16':\n",
    "        model = models.vgg16(weights=models.VGG16_Weights.DEFAULT)\n",
    "        in_features = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(in_features, cfg.NUM_CLASSES)\n",
    "    elif best_model_name == 'convnext':\n",
    "        model = models.convnext_small(weights=models.ConvNeXt_Small_Weights.DEFAULT)\n",
    "        in_features = model.classifier[2].in_features\n",
    "        model.classifier[2] = nn.Linear(in_features, cfg.NUM_CLASSES)\n",
    "    elif best_model_name == 'efficientnet':\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        in_features = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_features, cfg.NUM_CLASSES)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(best_model_result['model_path'], map_location=device)['model_state_dict'])\n",
    "    model.eval()\n",
    "    print(f\"✅ Best model loaded successfully!\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(f\"\\n2. Evaluating best model on test set...\")\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_loader, desc='Test evaluation', ncols=100)\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_true.extend(labels.cpu().numpy())\n",
    "            all_pred.extend(predicted.cpu().numpy())\n",
    "            pbar.set_postfix({'test_acc': f'{100*correct/total:.2f}%'})\n",
    "    \n",
    "    test_acc = 100 * correct / total\n",
    "    print(f\"✅ Test accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    # Save test confusion matrix\n",
    "    test_cm_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{best_model_name}_test_confusion_matrix.png\")\n",
    "    plot_confusion_matrix(all_true, all_pred, cfg.CLASS_NAMES, best_model_name, test_cm_path, split='Test Set')\n",
    "    \n",
    "    # Random inference on test sample\n",
    "    print(f\"\\n3. Random inference on test sample...\")\n",
    "    idx = np.random.randint(0, len(test_dataset))\n",
    "    img, label = test_dataset[idx]\n",
    "    with torch.no_grad():\n",
    "        img_tensor = img.unsqueeze(0).to(device)\n",
    "        pred = model(img_tensor).argmax(dim=1).item()\n",
    "    \n",
    "    print(f\"  Test sample index: {idx}\")\n",
    "    print(f\"  Ground truth: {cfg.CLASS_NAMES[label]}\")\n",
    "    print(f\"  Prediction: {cfg.CLASS_NAMES[pred]}\")\n",
    "    \n",
    "    # Visualize inference sample\n",
    "    print(f\"\\n4. Visualizing inference sample...\")\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    img_show = img.cpu() * std + mean\n",
    "    img_show = img_show.permute(1, 2, 0).numpy()\n",
    "    img_show = np.clip(img_show, 0, 1)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img_show)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Best Model: {best_model_name}\\nTest Inference - GT: {cfg.CLASS_NAMES[label]} | Pred: {cfg.CLASS_NAMES[pred]}', fontsize=14)\n",
    "    infer_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{best_model_name}_test_infer_sample.png\")\n",
    "    infer_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{best_model_name}_test_infer_sample.png\")\n",
    "    plt.savefig(infer_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ Inference visualization saved: {os.path.basename(infer_path)}\")\n",
    "\n",
    "print(\"\\n✅ Test evaluation and inference completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T12:13:43.453864Z",
     "iopub.status.busy": "2025-11-14T12:13:43.452924Z",
     "iopub.status.idle": "2025-11-14T12:13:51.395298Z",
     "shell.execute_reply": "2025-11-14T12:13:51.394078Z",
     "shell.execute_reply.started": "2025-11-14T12:13:43.453821Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config1:\n",
    "    NUM_CLASSES = 2\n",
    "    CLASS_NAMES = ['cat', 'dog']\n",
    "    VIS_SAVE_DIR = '/kaggle/working/visualization_results'\n",
    "    TEST_DATASET_PATH = '/kaggle/input/testdataset/test'\n",
    "    # Preprocessing must match training configuration\n",
    "    TEST_TRANSFORM = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.446), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "cfg1 = Config1()\n",
    "\n",
    "os.makedirs(cfg.VIS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Load test dataset\n",
    "from torchvision import datasets\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root=cfg1.TEST_DATASET_PATH,\n",
    "    transform=cfg1.TEST_TRANSFORM\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"✅ Test dataset loaded successfully!\")\n",
    "print(f\"Total samples: {len(test_dataset)}\")\n",
    "print(f\"Class mapping: {test_dataset.class_to_idx}\")\n",
    "print(f\"Cat samples: {len([img for img, label in test_dataset if label == 0])}\")\n",
    "print(f\"Dog samples: {len([img for img, label in test_dataset if label == 1])}\")\n",
    "\n",
    "# Testing\n",
    "print(f\"\\n2. Evaluating best model on test set...\")\n",
    "correct = 0\n",
    "total = 0\n",
    "all_true = []\n",
    "all_pred = []\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(test_loader, desc='Test Evaluation', ncols=100)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        all_true.extend(labels.cpu().numpy())\n",
    "        all_pred.extend(predicted.cpu().numpy())\n",
    "        all_images.extend(images.cpu())\n",
    "        all_labels.extend(labels.cpu())\n",
    "        \n",
    "        pbar.set_postfix({'test_acc': f'{100*correct/total:.2f}%'})\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"✅ Test accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "test_cm_path = os.path.join(cfg1.VIS_SAVE_DIR, f\"{best_model_name}_test_confusion_matrix.png\")\n",
    "plot_confusion_matrix(all_true, all_pred, cfg1.CLASS_NAMES, best_model_name, test_cm_path, split='Test Set')\n",
    "\n",
    "# Random sample from test dataset\n",
    "print(f\"\\n3. Random sample inference from test dataset...\")\n",
    "idx = np.random.randint(0, len(test_dataset))\n",
    "img, label = test_dataset[idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "    img_tensor = img.unsqueeze(0).to(device)\n",
    "    pred = model(img_tensor).argmax(dim=1).item()\n",
    "\n",
    "true_class = cfg1.CLASS_NAMES[label]\n",
    "pred_class = cfg1.CLASS_NAMES[pred]\n",
    "\n",
    "print(f\"  Test sample index: {idx}\")\n",
    "print(f\"  True class: {true_class}\")\n",
    "print(f\"  Predicted class: {pred_class}\")\n",
    "print(f\"  Result: {'✅ Correct' if true_class == pred_class else '❌ Incorrect'}\")\n",
    "\n",
    "# Visualization\n",
    "print(f\"\\n4. Visualizing inference sample...\")\n",
    "mean = torch.tensor([0.485, 0.456, 0.446]).view(3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "img_show = img.cpu() * std + mean\n",
    "img_show = img_show.permute(1, 2, 0).numpy()\n",
    "img_show = np.clip(img_show, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img_show)\n",
    "plt.axis('off')\n",
    "plt.title(\n",
    "    f'Best Model: {best_model_name}\\nTest Set Inference\\n'\n",
    "    f'True Class: {true_class} | Predicted: {pred_class}',\n",
    "    fontsize=14\n",
    ")\n",
    "infer_path = os.path.join(cfg1.VIS_SAVE_DIR, f\"{best_model_name}_test_infer_sample.png\")\n",
    "plt.savefig(infer_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"✅ Inference sample visualization saved: {os.path.basename(infer_path)}\")\n",
    "\n",
    "def plot_correct_incorrect_samples(all_images, all_true, all_pred, class_names, save_path):\n",
    "    \"\"\"Visualize correct and incorrect predictions (4 samples each)\"\"\"\n",
    "    correct_idxs = [i for i, (t, p) in enumerate(zip(all_true, all_pred)) if t == p]\n",
    "    incorrect_idxs = [i for i, (t, p) in enumerate(zip(all_true, all_pred)) if t != p]\n",
    "    \n",
    "    selected_correct = np.random.choice(correct_idxs, min(4, len(correct_idxs)), replace=False)\n",
    "    selected_incorrect = np.random.choice(incorrect_idxs, min(4, len(incorrect_idxs)), replace=False)\n",
    "    selected_idxs = np.concatenate([selected_correct, selected_incorrect])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(selected_idxs), figsize=(4*len(selected_idxs), 5))\n",
    "    if len(selected_idxs) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, ax in zip(selected_idxs, axes):\n",
    "        img = all_images[idx]\n",
    "        true_label = all_true[idx]\n",
    "        pred_label = all_pred[idx]\n",
    "        \n",
    "        img_show = img * std + mean\n",
    "        img_show = img_show.permute(1, 2, 0).numpy()\n",
    "        img_show = np.clip(img_show, 0, 1)\n",
    "        \n",
    "        true_class = class_names[true_label]\n",
    "        pred_class = class_names[pred_label]\n",
    "        status = \"Correct\" if true_label == pred_label else \"Incorrect\"\n",
    "        color = 'green' if status == \"Correct\" else 'red'\n",
    "        \n",
    "        ax.imshow(img_show)\n",
    "        ax.set_title(f\"True: {true_class}\\nPred: {pred_class}\\n{status}\", color=color, fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{best_model_name} Test Set Prediction Samples', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ Correct/incorrect samples visualization saved: {os.path.basename(save_path)}\")\n",
    "\n",
    "sample_vis_path = os.path.join(cfg1.VIS_SAVE_DIR, f\"{best_model_name}_test_correct_incorrect_samples.png\")\n",
    "plot_correct_incorrect_samples(all_images, all_true, all_pred, cfg1.CLASS_NAMES, sample_vis_path)\n",
    "\n",
    "print(\"\\n✅ Test set evaluation and inference completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T12:15:43.874390Z",
     "iopub.status.busy": "2025-11-14T12:15:43.873659Z",
     "iopub.status.idle": "2025-11-14T12:15:47.542822Z",
     "shell.execute_reply": "2025-11-14T12:15:47.542061Z",
     "shell.execute_reply.started": "2025-11-14T12:15:43.874360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"\\n2. Evaluating best model on Test set...\")\n",
    "correct = 0\n",
    "total = 0\n",
    "all_true = []\n",
    "all_pred = []\n",
    "all_images = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(test_loader, desc='Test Evaluation', ncols=100)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        all_true.extend(labels.cpu().numpy())\n",
    "        all_pred.extend(predicted.cpu().numpy())\n",
    "        all_images.extend(images.cpu())\n",
    "        \n",
    "        pbar.set_postfix({'test_acc': f'{100*correct/total:.2f}%'})\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f\"✅ Test Set Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "test_cm_path = os.path.join(cfg1.VIS_SAVE_DIR, f\"{best_model_name}_test_confusion_matrix.png\")\n",
    "plot_confusion_matrix(all_true, all_pred, cfg1.CLASS_NAMES, best_model_name, test_cm_path, split='Test Set')\n",
    "\n",
    "# Random samples from test dataset\n",
    "print(f\"\\n3. Random sample inference from Test dataset...\")\n",
    "idx = np.random.randint(0, len(test_dataset))\n",
    "img, label = test_dataset[idx]\n",
    "\n",
    "with torch.no_grad():\n",
    "    img_tensor = img.unsqueeze(0).to(device)\n",
    "    pred = model(img_tensor).argmax(dim=1).item()\n",
    "\n",
    "true_class = cfg1.CLASS_NAMES[label]\n",
    "pred_class = cfg1.CLASS_NAMES[pred]\n",
    "\n",
    "print(f\"  Test sample index: {idx}\")\n",
    "print(f\"  True class: {true_class}\")\n",
    "print(f\"  Predicted class: {pred_class}\")\n",
    "print(f\"  Result: {'✅ Correct' if true_class == pred_class else '❌ Incorrect'}\")\n",
    "\n",
    "# Visualization\n",
    "print(f\"\\n4. Visualizing inference sample...\")\n",
    "mean = torch.tensor([0.485, 0.456, 0.446]).view(3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "img_show = img.cpu() * std + mean\n",
    "img_show = img_show.permute(1, 2, 0).numpy()\n",
    "img_show = np.clip(img_show, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img_show)\n",
    "plt.axis('off')\n",
    "plt.title(\n",
    "    f'Best Model: {best_model_name}\\nTest Set Inference\\n'\n",
    "    f'True Class: {true_class} | Predicted Class: {pred_class}',\n",
    "    fontsize=14\n",
    ")\n",
    "infer_path = os.path.join(cfg1.VIS_SAVE_DIR, f\"{best_model_name}_test_infer_sample.png\")\n",
    "plt.savefig(infer_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"✅ Inference sample visualization saved: {os.path.basename(infer_path)}\")\n",
    "\n",
    "def plot_correct_incorrect_samples(all_images, all_true, all_pred, class_names, save_path):\n",
    "    \"\"\"Visualize correct and incorrect prediction samples (4 each)\"\"\"\n",
    "    # Separate correct/incorrect indices\n",
    "    correct_idxs = [int(i) for i, (t, p) in enumerate(zip(all_true, all_pred)) if t == p]\n",
    "    incorrect_idxs = [int(i) for i, (t, p) in enumerate(zip(all_true, all_pred)) if t != p]\n",
    "    \n",
    "    # Handle empty lists\n",
    "    selected_correct = []\n",
    "    if len(correct_idxs) > 0:\n",
    "        selected_correct = np.random.choice(\n",
    "            correct_idxs, min(4, len(correct_idxs)), replace=False\n",
    "        ).astype(int).tolist()\n",
    "    \n",
    "    selected_incorrect = []\n",
    "    if len(incorrect_idxs) > 0:\n",
    "        selected_incorrect = np.random.choice(\n",
    "            incorrect_idxs, min(4, len(incorrect_idxs)), replace=False\n",
    "        ).astype(int).tolist()\n",
    "    \n",
    "    selected_idxs = selected_correct + selected_incorrect\n",
    "    if len(selected_idxs) == 0:\n",
    "        print(\"⚠️  No samples available for visualization\")\n",
    "        return\n",
    "    \n",
    "    # Plot subplots\n",
    "    fig, axes = plt.subplots(1, len(selected_idxs), figsize=(4*len(selected_idxs), 5))\n",
    "    if len(selected_idxs) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, ax in zip(selected_idxs, axes):\n",
    "        img = all_images[idx]\n",
    "        true_label = int(all_true[idx])\n",
    "        pred_label = int(all_pred[idx])\n",
    "        \n",
    "        # Denormalize image\n",
    "        img_show = img * std + mean\n",
    "        img_show = img_show.permute(1, 2, 0).numpy()\n",
    "        img_show = np.clip(img_show, 0, 1)\n",
    "        \n",
    "        true_class = class_names[true_label]\n",
    "        pred_class = class_names[pred_label]\n",
    "        status = \"Correct\" if true_label == pred_label else \"Incorrect\"\n",
    "        color = 'green' if status == \"Correct\" else 'red'\n",
    "        \n",
    "        ax.imshow(img_show)\n",
    "        ax.set_title(f\"True: {true_class}\\nPred: {pred_class}\\n{status}\", color=color, fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{best_model_name} Test Set Prediction Samples', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ Correct/incorrect samples visualization saved: {os.path.basename(save_path)}\")\n",
    "\n",
    "sample_vis_path = os.path.join(cfg1.VIS_SAVE_DIR, f\"{best_model_name}_test_correct_incorrect_samples.png\")\n",
    "plot_correct_incorrect_samples(all_images, all_true, all_pred, cfg1.CLASS_NAMES, sample_vis_path)\n",
    "\n",
    "print(\"\\n✅ Best model Test set evaluation and inference completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T12:22:52.994292Z",
     "iopub.status.busy": "2025-11-14T12:22:52.993661Z",
     "iopub.status.idle": "2025-11-14T12:28:47.153286Z",
     "shell.execute_reply": "2025-11-14T12:28:47.152187Z",
     "shell.execute_reply.started": "2025-11-14T12:22:52.994270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# GPU detection\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Configuration parameters\n",
    "class Config2:\n",
    "    DATA_ROOT = './cifar10_data'\n",
    "    MODEL_NAME = 'convnext_tiny'\n",
    "    IMG_SIZE = 32\n",
    "    NUM_CLASSES = 10\n",
    "    BATCH_SIZE = 128\n",
    "    NUM_EPOCHS = 15\n",
    "    LEARNING_RATE = 0.001\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    NUM_WORKERS = 2\n",
    "    PIN_MEMORY = True\n",
    "    LR_SCHEDULER_PATIENCE = 3\n",
    "    LR_SCHEDULER_FACTOR = 0.5\n",
    "    VAL_SPLIT = 0.2\n",
    "    VIS_SAVE_DIR = './cifar10_visualizations'\n",
    "    NUM_SAMPLE_GRID = 16\n",
    "    CM_FIGSIZE = (12, 10)\n",
    "    SAMPLE_FIGSIZE = (16, 12)\n",
    "    CLASS_NAMES = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "cfg2 = Config2()\n",
    "os.makedirs(cfg2.VIS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.446), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.446), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "full_train_dataset = datasets.CIFAR10(\n",
    "    root=cfg2.DATA_ROOT, train=True, download=True, transform=train_transform\n",
    ")\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root=cfg2.DATA_ROOT, train=False, download=True, transform=val_test_transform\n",
    ")\n",
    "\n",
    "# Split train and validation sets\n",
    "val_size = int(cfg2.VAL_SPLIT * len(full_train_dataset))\n",
    "train_size = len(full_train_dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "val_dataset.dataset.transform = val_test_transform\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=cfg2.BATCH_SIZE, shuffle=True,\n",
    "    num_workers=cfg2.NUM_WORKERS, pin_memory=cfg2.PIN_MEMORY\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=cfg2.BATCH_SIZE, shuffle=False,\n",
    "    num_workers=cfg2.NUM_WORKERS, pin_memory=cfg2.PIN_MEMORY\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=cfg2.BATCH_SIZE, shuffle=False,\n",
    "    num_workers=cfg2.NUM_WORKERS, pin_memory=cfg2.PIN_MEMORY\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Class names: {cfg2.CLASS_NAMES}\")\n",
    "\n",
    "# Build ConvNeXt model\n",
    "def build_convnext(num_classes=10):\n",
    "    \"\"\"Load ConvNeXt Tiny and adapt for CIFAR-10\"\"\"\n",
    "    model = models.convnext_tiny(pretrained=True)\n",
    "    in_features = model.classifier[2].in_features\n",
    "    model.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "model = build_convnext(num_classes=cfg2.NUM_CLASSES)\n",
    "print(f\"\\n{cfg2.MODEL_NAME} Model initialized:\")\n",
    "print(f\"Model structure: {model}\")\n",
    "\n",
    "# Loss function, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), lr=cfg2.LEARNING_RATE, weight_decay=cfg2.WEIGHT_DECAY\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=cfg2.LR_SCHEDULER_FACTOR,\n",
    "    patience=cfg2.LR_SCHEDULER_PATIENCE, verbose=True\n",
    ")\n",
    "\n",
    "# Training function\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc='Train', ncols=100)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/total:.4f}',\n",
    "            'acc': f'{100*correct/total:.2f}%'\n",
    "        })\n",
    "\n",
    "    return running_loss / total, 100 * correct / total\n",
    "\n",
    "# Validation/Test function\n",
    "def validate(model, loader, criterion, device, return_preds=False):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_images = []\n",
    "\n",
    "    pbar = tqdm(loader, desc='Valid/Test', ncols=100)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if return_preds:\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_images.extend(images.cpu())\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss/total:.4f}',\n",
    "                'acc': f'{100*correct/total:.2f}%'\n",
    "            })\n",
    "\n",
    "    avg_loss = running_loss / total\n",
    "    avg_acc = 100 * correct / total\n",
    "\n",
    "    if return_preds:\n",
    "        return avg_loss, avg_acc, all_preds, all_labels, all_images\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "# Visualization\n",
    "def plot_training_curves(history, save_path):\n",
    "    \"\"\"Plot training accuracy and loss curves\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_acc'], label='Train Acc', marker='o', linewidth=2)\n",
    "    plt.plot(history['val_acc'], label='Val Acc', marker='s', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title(f'{cfg2.MODEL_NAME} Training/Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_loss'], label='Train Loss', marker='o', linewidth=2)\n",
    "    plt.plot(history['val_loss'], label='Val Loss', marker='s', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{cfg2.MODEL_NAME} Training/Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    print(f\"✅ Training curves saved to: {save_path}\")\n",
    "\n",
    "def plot_confusion_matrix(all_labels, all_preds, class_names, save_path):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=cfg2.CM_FIGSIZE)\n",
    "    \n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    sns.heatmap(\n",
    "        cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "        xticklabels=class_names, yticklabels=class_names\n",
    "    )\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'{cfg2.MODEL_NAME} Confusion Matrix (Test Set)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nClassification Report (Test Set):\")\n",
    "    print(classification_report(\n",
    "        all_labels, all_preds, target_names=class_names, digits=4\n",
    "    ))\n",
    "    print(f\"✅ Confusion matrix saved to: {save_path}\")\n",
    "\n",
    "def denormalize_image(tensor):\n",
    "    \"\"\"Denormalize image for visualization\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.446]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return tensor * std + mean\n",
    "\n",
    "def plot_sample_analysis(all_images, all_labels, all_preds, class_names, save_path):\n",
    "    \"\"\"Visualize correct and incorrect predictions\"\"\"\n",
    "    correct_idxs = [i for i, (p, l) in enumerate(zip(all_preds, all_labels)) if p == l]\n",
    "    incorrect_idxs = [i for i, (p, l) in enumerate(zip(all_preds, all_labels)) if p != l]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=cfg2.SAMPLE_FIGSIZE)\n",
    "    \n",
    "    axes[0].set_title(f'Correct Predictions (Test Set) - {len(correct_idxs)} samples', fontsize=14)\n",
    "    num_correct = min(cfg2.NUM_SAMPLE_GRID, len(correct_idxs))\n",
    "    selected_correct = np.random.choice(correct_idxs, num_correct, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(selected_correct):\n",
    "        img = denormalize_image(all_images[idx])\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        ax = plt.subplot(2, cfg2.NUM_SAMPLE_GRID//2, i+1)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"True: {class_names[all_labels[idx]]}\\nPred: {class_names[all_preds[idx]]}\", fontsize=8)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    axes[1].set_title(f'Incorrect Predictions (Test Set) - {len(incorrect_idxs)} samples', fontsize=14)\n",
    "    num_incorrect = min(cfg2.NUM_SAMPLE_GRID, len(incorrect_idxs))\n",
    "    if num_incorrect > 0:\n",
    "        selected_incorrect = np.random.choice(incorrect_idxs, num_incorrect, replace=False)\n",
    "        for i, idx in enumerate(selected_incorrect):\n",
    "            img = denormalize_image(all_images[idx])\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "            \n",
    "            ax = plt.subplot(2, cfg2.NUM_SAMPLE_GRID//2, num_correct + i + 1)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"True: {class_names[all_labels[idx]]}\\nPred: {class_names[all_preds[idx]]}\", fontsize=8)\n",
    "            ax.axis('off')\n",
    "    else:\n",
    "        axes[1].text(0.5, 0.5, 'No Incorrect Predictions!', ha='center', va='center', fontsize=16)\n",
    "        axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    print(f\"✅ Sample analysis saved to: {save_path}\")\n",
    "\n",
    "best_val_acc = 0.0\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': []\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"CIFAR-10 {cfg2.MODEL_NAME} Training Started (Epochs: {cfg2.NUM_EPOCHS})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(cfg2.NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{cfg2.NUM_EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}% | \"\n",
    "          f\"LR: {current_lr:.6f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        model_save_path = os.path.join(cfg2.VIS_SAVE_DIR, f\"{cfg2.MODEL_NAME}_best.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'history': history\n",
    "        }, model_save_path)\n",
    "        print(f\"  [Saved] Best model (Val Acc: {val_acc:.2f}%) to: {model_save_path}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(f\"\\nTraining Finished! Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "# Test set evaluation with visualization\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Test Set Evaluation for {cfg2.MODEL_NAME}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checkpoint = torch.load(model_save_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print(f\"Loaded best model (trained for {checkpoint['epoch']+1} epochs)\")\n",
    "\n",
    "test_loss, test_acc, test_preds, test_labels, test_images = validate(\n",
    "    model, test_loader, criterion, device, return_preds=True\n",
    ")\n",
    "print(f\"\\nTest Set Results: Loss = {test_loss:.4f}, Acc = {test_acc:.2f}%\")\n",
    "\n",
    "# Generate visualizations\n",
    "print(f\"\\n===== Generating {cfg2.MODEL_NAME} Visualization Analysis (Test Set) =====\")\n",
    "\n",
    "curve_path = os.path.join(cfg2.VIS_SAVE_DIR, f\"{cfg2.MODEL_NAME}_training_curves.png\")\n",
    "plot_training_curves(history, curve_path)\n",
    "\n",
    "cm_path = os.path.join(cfg2.VIS_SAVE_DIR, f\"{cfg2.MODEL_NAME}_test_confusion_matrix.png\")\n",
    "plot_confusion_matrix(test_labels, test_preds, cfg2.CLASS_NAMES, cm_path)\n",
    "\n",
    "sample_path = os.path.join(cfg2.VIS_SAVE_DIR, f\"{cfg2.MODEL_NAME}_test_sample_analysis.png\")\n",
    "plot_sample_analysis(test_images, test_labels, test_preds, cfg2.CLASS_NAMES, sample_path)\n",
    "\n",
    "# Save results\n",
    "all_model_results = {}\n",
    "all_model_results[cfg2.MODEL_NAME] = {\n",
    "    'val_acc': best_val_acc,\n",
    "    'test_acc': test_acc,\n",
    "    'test_loss': test_loss,\n",
    "    'history': history,\n",
    "    'model_path': model_save_path,\n",
    "    'test_preds': test_preds,\n",
    "    'test_labels': test_labels\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ {cfg2.MODEL_NAME} Training + Testing + Visualization Complete!\")\n",
    "print(f\"Visualization files saved to: {cfg2.VIS_SAVE_DIR}\")\n",
    "print(f\"Trained models: {list(all_model_results.keys())}\")\n",
    "print(f\"Final test accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T12:31:30.122295Z",
     "iopub.status.busy": "2025-11-14T12:31:30.121591Z",
     "iopub.status.idle": "2025-11-14T12:31:33.216560Z",
     "shell.execute_reply": "2025-11-14T12:31:33.215696Z",
     "shell.execute_reply.started": "2025-11-14T12:31:30.122271Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_sample_analysis(all_images, all_labels, all_preds, class_names, save_path):\n",
    "    # Separate correct and incorrect predictions\n",
    "    correct_idxs = [int(i) for i, (p, l) in enumerate(zip(all_preds, all_labels)) if p == l]\n",
    "    incorrect_idxs = [int(i) for i, (p, l) in enumerate(zip(all_preds, all_labels)) if p != l]\n",
    "\n",
    "    # Maximum samples to display per section\n",
    "    max_samples_per_section = cfg2.NUM_SAMPLE_GRID\n",
    "    num_correct = min(max_samples_per_section, len(correct_idxs))\n",
    "    num_incorrect = min(max_samples_per_section, len(incorrect_idxs))\n",
    "    \n",
    "    # Calculate total rows needed\n",
    "    total_rows = 0\n",
    "    if num_correct > 0:\n",
    "        total_rows += 1\n",
    "    if num_incorrect > 0:\n",
    "        total_rows += 1\n",
    "    if total_rows == 0:\n",
    "        print(\"⚠️  No samples available for visualization\")\n",
    "        return\n",
    "    \n",
    "    # Create figure with dynamic row adjustment\n",
    "    fig = plt.figure(figsize=(cfg2.SAMPLE_FIGSIZE[0], cfg2.SAMPLE_FIGSIZE[1] * total_rows / 2))\n",
    "    \n",
    "    # Plot correct predictions (if any)\n",
    "    if num_correct > 0:\n",
    "        correct_selected = np.random.choice(correct_idxs, num_correct, replace=False).astype(int)\n",
    "        for i, idx in enumerate(correct_selected):\n",
    "            ax = plt.subplot(total_rows, num_correct, i + 1)\n",
    "            img = denormalize_image(all_images[idx])\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"True: {class_names[all_labels[idx]]}\\nPred: {class_names[all_preds[idx]]}\", fontsize=8)\n",
    "            ax.axis('off')\n",
    "        fig.suptitle(f'Correct Predictions (Test Set) - {len(correct_idxs)} total samples', fontsize=14, y=0.95)\n",
    "    \n",
    "    # Plot incorrect predictions\n",
    "    if num_incorrect > 0:\n",
    "        incorrect_selected = np.random.choice(incorrect_idxs, num_incorrect, replace=False).astype(int)\n",
    "        row_offset = 1 if num_correct > 0 else 0\n",
    "        for i, idx in enumerate(incorrect_selected):\n",
    "            ax = plt.subplot(total_rows, num_incorrect, row_offset * num_incorrect + i + 1)\n",
    "            img = denormalize_image(all_images[idx])\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"True: {class_names[all_labels[idx]]}\\nPred: {class_names[all_preds[idx]]}\", fontsize=8, color='red')\n",
    "            ax.axis('off')\n",
    "        \n",
    "        if num_correct > 0:\n",
    "            fig.text(0.5, 0.47, f'Incorrect Predictions (Test Set) - {len(incorrect_idxs)} total samples', \n",
    "                    fontsize=14, ha='center')\n",
    "        else:\n",
    "            fig.suptitle(f'Incorrect Predictions (Test Set) - {len(incorrect_idxs)} total samples', fontsize=14, y=0.95)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    print(f\"✅ Sample analysis saved to: {save_path}\")\n",
    "\n",
    "# Visualization\n",
    "sample_path = os.path.join(cfg2.VIS_SAVE_DIR, f\"{cfg2.MODEL_NAME}_test_sample_analysis.png\")\n",
    "plot_sample_analysis(test_images, test_labels, test_preds, cfg2.CLASS_NAMES, sample_path)\n",
    "\n",
    "# Save results\n",
    "all_model_results = {}\n",
    "all_model_results[cfg2.MODEL_NAME] = {\n",
    "    'val_acc': best_val_acc,\n",
    "    'test_acc': test_acc,\n",
    "    'test_loss': test_loss,\n",
    "    'history': history,\n",
    "    'model_path': model_save_path,\n",
    "    'test_preds': test_preds,\n",
    "    'test_labels': test_labels\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ {cfg2.MODEL_NAME} training + testing + visualization completed!\")\n",
    "print(f\"Visualization files saved to: {cfg2.VIS_SAVE_DIR}\")\n",
    "print(f\"Trained models: {list(all_model_results.keys())}\")\n",
    "print(f\"Final test accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T13:33:12.268809Z",
     "iopub.status.busy": "2025-11-14T13:33:12.268407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU Detection\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Global Configuration \n",
    "class Config:\n",
    "    # Data Configuration\n",
    "    DATASET_NAME = 'Aurora1609/cat_vs_dog'\n",
    "    IMG_SIZE = 224\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_WORKERS = 0\n",
    "    PIN_MEMORY = False\n",
    "    \n",
    "    # Training Configuration\n",
    "    NUM_EPOCHS = 20\n",
    "    NUM_CLASSES = 2\n",
    "    LEARNING_RATE = 0.0001\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    LR_SCHEDULER_PATIENCE = 3\n",
    "    LR_SCHEDULER_FACTOR = 0.5\n",
    "\n",
    "    # Saving Configuration\n",
    "    MODEL_SAVE_DIR = './saved_models'\n",
    "    VIS_SAVE_DIR = './visualization_results'\n",
    "    CLASS_NAMES = ['cat', 'dog']\n",
    "    NUM_SAMPLE_GRID = 16\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# Create save directories\n",
    "os.makedirs(cfg.MODEL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(cfg.VIS_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Global dictionary: store results of all models (val_acc, test_acc, history)\n",
    "all_model_results = {}\n",
    "\n",
    "# Visualization utility functions\n",
    "def plot_single_model_curve(history, model_name, save_path):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    # Accuracy curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_acc'], 'b-o', label='Train Acc', markersize=4)\n",
    "    plt.plot(history['val_acc'], 'r-o', label='Val Acc', markersize=4)\n",
    "    plt.title(f'{model_name} - Accuracy Curve', fontsize=12)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    # Loss curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_loss'], 'b-o', label='Train Loss', markersize=4)\n",
    "    plt.plot(history['val_loss'], 'r-o', label='Val Loss', markersize=4)\n",
    "    plt.title(f'{model_name} - Loss Curve', fontsize=12)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✅ Training curve saved: {os.path.basename(save_path)}\")\n",
    "\n",
    "def plot_confusion_matrix(all_true, all_pred, class_names, model_name, save_path, split='Val Set'):\n",
    "    cm = confusion_matrix(all_true, all_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt='d', cmap='Blues',\n",
    "        xticklabels=class_names, yticklabels=class_names,\n",
    "        cbar_kws={'label': 'Number of Samples'}\n",
    "    )\n",
    "    plt.title(f'{model_name} - Confusion Matrix ({split})', fontsize=14)\n",
    "    plt.xlabel('Predicted', fontsize=12)\n",
    "    plt.ylabel('True', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix saved: {os.path.basename(save_path)}\")\n",
    "\n",
    "def plot_sample_analysis(model, val_loader, class_names, device, model_name, save_dir, num_samples=16):\n",
    "    model.eval()\n",
    "    correct_imgs, correct_lbls, correct_preds = [], [], []\n",
    "    incorrect_imgs, incorrect_lbls, incorrect_preds = [], [], []\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).to(device).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).to(device).view(3, 1, 1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            lbls = lbls.to(device)\n",
    "            preds = model(imgs).argmax(dim=1)\n",
    "            for img, lbl, pred in zip(imgs, lbls, preds):\n",
    "                if lbl == pred:\n",
    "                    correct_imgs.append(img)\n",
    "                    correct_lbls.append(lbl)\n",
    "                    correct_preds.append(pred)\n",
    "                else:\n",
    "                    incorrect_imgs.append(img)\n",
    "                    incorrect_lbls.append(lbl)\n",
    "                    incorrect_preds.append(pred)\n",
    "            if len(correct_imgs)>=num_samples and len(incorrect_imgs)>=num_samples:\n",
    "                break\n",
    "\n",
    "    # Correct prediction samples\n",
    "    if len(correct_imgs)>=num_samples:\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "        fig.suptitle(f'{model_name} - Correct Predictions (Val Set)', fontsize=18, y=0.95)\n",
    "        for idx, (img, t_lbl, p_lbl) in enumerate(zip(correct_imgs[:num_samples], correct_lbls[:num_samples], correct_preds[:num_samples])):\n",
    "            img = img.squeeze().cpu() * std.cpu() + mean.cpu()\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "            ax = axes[idx//4, idx%4]\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"True: {class_names[t_lbl.item()]}\\nPredict: {class_names[p_lbl.item()]}\", color='green', fontsize=12, pad=10)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "        plt.savefig(os.path.join(save_dir, f\"{model_name}_correct_samples.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Correct prediction samples saved: {model_name}_correct_samples.png\")\n",
    "    \n",
    "    # Incorrect prediction samples\n",
    "    if len(incorrect_imgs)>=num_samples:\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "        fig.suptitle(f'{model_name} - Incorrect Predictions (Val Set)', fontsize=18, y=0.95)\n",
    "        for idx, (img, t_lbl, p_lbl) in enumerate(zip(incorrect_imgs[:num_samples], incorrect_lbls[:num_samples], incorrect_preds[:num_samples])):\n",
    "            img = img.squeeze().cpu() * std.cpu() + mean.cpu()\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "            ax = axes[idx//4, idx%4]\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            ax.set_title(f\"True: {class_names[t_lbl.item()]}\\nPred: {class_names[p_lbl.item()]}\", color='red', fontsize=12, pad=10)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "        plt.savefig(os.path.join(save_dir, f\"{model_name}_incorrect_samples.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"Incorrect prediction samples saved: {model_name}_incorrect_samples.png\")\n",
    "    else:\n",
    "        print(f\"{model_name}: Insufficient incorrect samples ({len(incorrect_imgs)} < {num_samples}), skipping incorrect sample plot\")\n",
    "\n",
    "# Training/validation utility functions \n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(loader, desc='Training', ncols=100)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        pbar.set_postfix({'loss': f'{running_loss/total:.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
    "    return running_loss / total, 100 * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    pbar = tqdm(loader, desc='Validation', ncols=100)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_true.extend(labels.cpu().numpy())\n",
    "            all_pred.extend(predicted.cpu().numpy())\n",
    "            pbar.set_postfix({'loss': f'{running_loss/total:.4f}', 'acc': f'{100*correct/total:.2f}%'})\n",
    "    return running_loss / total, 100 * correct / total, all_true, all_pred\n",
    "\n",
    "# Dataset class with error handling for stability\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            item = self.dataset[idx]\n",
    "            image = item['image'].convert('RGB')\n",
    "            label = item['label']\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to load sample {idx}: {e}, returning fallback sample\")\n",
    "            item = self.dataset[0]\n",
    "            image = item['image'].convert('RGB')\n",
    "            label = item['label']\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "\n",
    "# Data preprocessing (shared across all models)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(cfg.IMG_SIZE, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((cfg.IMG_SIZE, cfg.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Load dataset (using built-in train/val/test split)\n",
    "print(f\"Loading dataset: {cfg.DATASET_NAME} (with built-in train/val/test split)...\")\n",
    "dataset = load_dataset(cfg.DATASET_NAME)\n",
    "train_hf = dataset['train']\n",
    "val_hf = dataset['val']\n",
    "test_hf = dataset['test']\n",
    "\n",
    "# Wrap dataset\n",
    "train_dataset = CatDogDataset(train_hf, train_transform)\n",
    "val_dataset = CatDogDataset(val_hf, val_test_transform)\n",
    "test_dataset = CatDogDataset(test_hf, val_test_transform)\n",
    "\n",
    "# Create DataLoader (single process to avoid errors)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True,\n",
    "    num_workers=cfg.NUM_WORKERS, pin_memory=cfg.PIN_MEMORY, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "    num_workers=cfg.NUM_WORKERS, pin_memory=cfg.PIN_MEMORY\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "    num_workers=cfg.NUM_WORKERS, pin_memory=cfg.PIN_MEMORY\n",
    ")\n",
    "\n",
    "# Print data information\n",
    "print(f\"\\nDataset Split Information:\")\n",
    "print(f\"  Training set samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation set samples: {len(val_dataset)}\")\n",
    "print(f\"  Test set samples: {len(test_dataset)}\")\n",
    "print(f\"  Classes: {cfg.CLASS_NAMES}\")\n",
    "\n",
    "# Model\n",
    "def build_efficientnet(num_classes=2, pretrained=True):\n",
    "    if pretrained:\n",
    "        try:\n",
    "            model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        except:\n",
    "            model = models.efficientnet_b0(pretrained=True)\n",
    "    else:\n",
    "        model = models.efficientnet_b0(pretrained=False)\n",
    "    # Modify final layer\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "# Initialize model\n",
    "model_name = 'efficientnet'\n",
    "print(f\"===== Starting training for model: {model_name} =====\")\n",
    "model = build_efficientnet(num_classes=cfg.NUM_CLASSES, pretrained=True)\n",
    "print(f\"{model_name} model initialized (pretrained weights: True)\")\n",
    "\n",
    "# Training configuration\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=cfg.LEARNING_RATE, weight_decay=cfg.WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=cfg.LR_SCHEDULER_FACTOR, patience=cfg.LR_SCHEDULER_PATIENCE, verbose=True\n",
    ")\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "best_all_true = []\n",
    "best_all_pred = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg.NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{cfg.NUM_EPOCHS}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    # Training\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    # Validation\n",
    "    val_loss, val_acc, all_true, all_pred = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Record history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Update best results\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_all_true = all_true\n",
    "        best_all_pred = all_pred\n",
    "        # Save best model\n",
    "        model_save_path = os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'val_acc': best_val_acc,\n",
    "            'history': history\n",
    "        }, model_save_path)\n",
    "        print(f\"[SAVED] Best model (Val Accuracy: {best_val_acc:.2f}%) → {os.path.basename(model_save_path)}\")\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch Summary: Train Loss={train_loss:.4f} Train Acc={train_acc:.2f}% | \"\n",
    "          f\"Val Loss={val_loss:.4f} Val Acc={val_acc:.2f}% | LR={current_lr:.6f}\")\n",
    "\n",
    "# Visualization\n",
    "print(f\"\\n===== Generating visualization analysis for {model_name} =====\")\n",
    "curve_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_training_curves.png\")\n",
    "plot_single_model_curve(history, model_name, curve_path)\n",
    "cm_path = os.path.join(cfg.VIS_SAVE_DIR, f\"{model_name}_val_confusion_matrix.png\")\n",
    "plot_confusion_matrix(best_all_true, best_all_pred, cfg.CLASS_NAMES, model_name, cm_path, split='Val Set')\n",
    "plot_sample_analysis(model, val_loader, cfg.CLASS_NAMES, device, model_name, cfg.VIS_SAVE_DIR, cfg.NUM_SAMPLE_GRID)\n",
    "\n",
    "# Save results\n",
    "all_model_results[model_name] = {\n",
    "    'val_acc': best_val_acc,\n",
    "    'history': history,\n",
    "    'model_path': os.path.join(cfg.MODEL_SAVE_DIR, f\"{model_name}_best.pth\")\n",
    "}\n",
    "\n",
    "print(f\"\\n{model_name} training + analysis completed\")\n",
    "print(f\"Currently trained models: {list(all_model_results.keys())}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8736789,
     "sourceId": 13731825,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
